install.packages("devtools")

library(prism)
library(devtools) #needed to download prism from github
library(raster) ##working with raster data
library(sp) ##manipulationg spatial data
library(rgdal)
library(doParallel) #allows parallel computing
library(foreach)  #need this with doparallel
library(ff)

rm(list=ls())

#1 code to extract prism data, inserted by JAS on 11_13_2018

#options(prism.path = "C:\\Users\\MimsLab\\Documents\\Ye\\Prism Data\\tmax") #path for prism data
#get_prism_annual(type = "tmax", year = 1981:1985, keepZip = FALSE)
#options(prism.path = "C:\\Users\\MimsLab\\Documents\\Ye\\Prism Data\\tmin") #path for prism data
#get_prism_annual(type = "tmin", year = 1981:1985, keepZip = FALSE)
#options(prism.path = "C:\\Users\\MimsLab\\Documents\\Ye\\Prism Data\\tmean") #path for prism data
#get_prism_annual(type = "tmean", year = 1981:1985, keepZip = FALSE)
#options(prism.path = "C:\\Users\\MimsLab\\Documents\\Ye\\Prism Data\\ppt") #path for prism data
#get_prism_annual(type = "ppt", year = 1981:1985, keepZip = FALSE)
#options(prism.path = "C:\\Users\\MimsLab\\Documents\\Ye\\Prism Data\\tmax Aug") #path for prism data
#get_prism_monthlys(type = "tmax", year = 1981:1985, mon = 8, keepZip = FALSE)
#options(prism.path = "C:\\Users\\MimsLab\\Documents\\Ye\\Prism Data\\tmin JAN") #path for prism data
#get_prism_monthlys(type = "tmin", year = 1981:1985, mon = 1, keepZip = FALSE)


#2 code extacts PRISM data to areas of occupancy described by buffers

FILES_buffer <- list.files(path="C:\\Users\\rrd600\\Documents\\FishProject\\1km points", pattern = "\\.shp$")#create file list for loop
options(prism.path = "C:\\Users\\rrd600\\Documents\\FishProject\\tmax Aug-20180826T171109Z-001\\tmax Aug") #path to all prism data, change the end to whatever metric

###1km buffer tmax
RS <- prism_stack(ls_prism_data()) #raster data
proj4string(RS)<-CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84")
prism_years <- t(ls_prism_data())
UseCores <- detectCores() -1 #detects one minus the max number of cores
cl <- makeCluster(UseCores) #create copies of R to run parallel
registerDoParallel(cl) #regist the cluster for parallel processing
foreach (i in c(3,9)) %dopar% {
  library(rgdal)
  library(raster) 
  library(ff)
  
  dat.name <- substr(FILES_buffer[i], 1, nchar(FILES_buffer[i])-4) #take the shape file name
  species <- readOGR("C:\\Users\\rrd600\\Documents\\FishProject\\1km buffers", dat.name) #read in the shapefile
  ext_ID1 <- extract(RS,species, buffer = 1000,fun= mean ,na.rm = T, weights = TRUE, small = TRUE, method = 'simple', df = TRUE) #change buffer size depending on AOO scale

 
  write.csv(ext_ID1, file =paste0("C:\\Users\\rrd600\\Documents\\FishProject\\Output\\1km\\test\\", dat.name,".csv"), row.names=FALSE) 
}

stopCluster(cl) #stop the parallel process
